@article{Regularization2012,
abstract = {Notwithstanding the popularity of conventional clustering algorithms such as K-means and probabilistic clustering, their clustering results are sensitive to the presence of outliers in the data. Even a few outliers can compromise the ability of these algorithms to identify meaningful hidden structures rendering their outcome unreliable. This paper develops robust clustering algorithms that not only aim to cluster the data, but also to identify the outliers. The novel approaches rely on the infrequent presence of outliers in the data, which translates to sparsity in a judiciously chosen domain. Leveraging sparsity in the outlier domain, outlier-aware robust K-means and probabilistic clustering approaches are proposed. Their novelty lies on identifying outliers while effecting sparsity in the outlier domain through carefully chosen regularization. A block coordinate descent approach is developed to obtain iterative algorithms with convergence guarantees and small excess computational complexity with respect to their non-robust counterparts. Kernelized versions of the robust clustering algorithms are also developed to efÔ¨Åciently handle high-dimensional data, identify nonlinearly separable clusters, or even cluster objects that arenot represented by vectors. Numerical tests on both synthetic and real datasets validate the performance and applicability of the novel algorithms.},
archivePrefix = {arXiv},
arxivId = {arXiv:1104.4512v1},
author = {Regularization, Outlier-sparsity and Forero, Pedro a and Member, Student and Kekatos, Vassilis and Giannakis, Georgios B},
doi = {10.1109/TSP.2012.2196696},
eprint = {arXiv:1104.4512v1},
file = {:Users/MiguelSilva/Documents/OneDrive - Universidade de Lisboa/IST/5 Ano/1 Semestre/OA - Optimiza{\c{c}}{\~{a}}o de Algoritmos/OA-Project/oaproject6.pdf:pdf},
journal = {IEEE Transactions on Signal Processing},
number = {234914},
pages = {4163--4177},
title = {{Robust Clustering Using}},
volume = {60},
year = {2012}
}
